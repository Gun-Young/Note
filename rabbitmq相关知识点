1.为什么引用消息中间件
	  参考文章： https://mp.weixin.qq.com/s/tiN6Z_VjTKZ5voFu4TFElg
	    
		1）系统解耦
		 系统A产生核心数据，将数据发送到消息中间件，然后由其他系统进行消费，不用直接接入其他系统，将系统进行解耦
		 
		 2）异步调用
		 假设有个系统调用链路，A调用B（20ms）, B调用C（200ms），c调用D(2s)，就是因为C调用D将性能降低了10倍，这时可以考虑
		 是不是可以将D系统从链路中抽离出去做成异步调用。
		 A调用B调用C（花费220ms），然后将消息发送到MQ,然后由D异步消费。这样将核心链路的性能提升10倍
		 
		3）流量削峰
        比如每秒几百个请求，一台机器就足够了，但是某段时间会出现瞬时高峰期，一下涌入每秒几万请求，这时我们可以使用MQ中间
		件进行流量削峰。在所有机器前面部署一层MQ,平时每秒几百请求可以轻松抗住，一旦到了瞬时高峰期，一下涌入几万的请求，
		就可以积压在MQ里面，然后慢慢处理和消费。
		这是很典型的一个MQ的用法，用有限的机器资源承载高并发请求，如果业务场景允许异步削峰，高峰期积压一些请求在MQ里，
		然后高峰期过了，后台系统在一定时间内消费完毕不再积压的话，那就很适合这种方案
        


      2. 引入消息中间件的缺点
	     参考文章： https://mp.weixin.qq.com/s/DsowfyzYXcD-OyiL1JOFZw
	     
		 A---->B----->C ------->MQ<------D
		 1） 系统可用性降低
			  万一MQ挂了,就导致整个业务流程中断了，多引入一个依赖，就会导致系统可用性的降低。所以就要考虑MQ如何部署，
			  以是实现保证系统的高可用。
			  解决方案：MQ高可用集群配置
			  
		2）系统稳定性降低
		      可能由于网络原因，C发送到MQ的消息丢失，或者发送两条一样的消息，可能导致整个系统业务的错乱。
			  也可能D系统宕机，导致无法消费消息，结果大量的消息在MQ中积压，即使D系统恢复了，也需要慢慢的消费处理
			  解决方案： 消息高可靠传递（0丢失），消息幂等性传递（不重复），百万消息积压的线上故障处理
			  
			  
		3）分布式一致性问题
		    比如C处理自己本地数据库成功了，然后发送一个消息MQ,系统D也的确消费了，但是D在操做自己本地数据库失败了。
			现在C成功了，D失败了，会导致系统整体数据不一致，此时需要分布式事务来保障
			解决方案：最终一致性   （https://mp.weixin.qq.com/s/yRDUQtVPz5eqCx961xL6nw）
			 
	  
	  3. 线上服务宕机时，如何保证数据100%不丢失
	     参考文章： https://mp.weixin.qq.com/s/HwAc6o8jdIHQTnE3ghXhIA
	     订单服务 -------> MQ <-------- 仓储服务（消费者）
         假如仓储服务,刚接收到一个订单消息，但是完成消息的处理之前，也就是还没对订单完成仓储调度发货，这是仓储服务挂掉，会发生什么？
         RabbitMq这个中间件默认的行为是自动ack, 仓储服务收到一个订单消息，rabbitmq就会立马把这条消息标记为删除，如果还没有处理完成
		 仓储服务就宕机了，那么这条消息就丢失了。
		 channel.basicConsume(QUEUE_NAME,true,deliverCallback,consumerTag->{});  //ture就是自动ack
		 这时，我们需要把true改为false,即手动进行ack,这样可以在合适的地方进行手动确认。
		 **手动ack工作机制:
			 手动ack时，我们先处理消息，完成后，再做ack响应，失败就不做ack响应，这样消息会存储在MQ的unacked消息里，不会丢。
			 但是这些消息会堆积在unacked消息里，不会抛弃，直至客户端断开重连时，才会变成ready;如果Consumer客户端不断开连接，
			 这些Unacked消息，永远不会变回ready状态。
		 **消费者处理消息失败
		    假如消费者处理消息失败，不能直接ack,合理的方式是使用nack操作，就是通知RabbitMq自己没有处理成功消息，然后让rabbitmq
			将这条消息再次投递给其他的消费者实例尝试去处理该消息。我们可以在catch代码块里加入以下代码
			channel.basicNack(delivery.getEnvelope().getDeliveryTag(),  true);
			注意：第二个参数是true,意思是让rabbitmq把这条消息重新投递给其他的消费者实例，因为自己没处理成功
			           false: 就会导致rabbitmq知道你处理失败，但是还是删除这条消息，这是不对的。
		 


     4. 消息中间件集群崩溃，如何保证百万成产数据不会丢失
	 订单服务（生产者） ----->  MQ  <--------仓储服务 （消费者）
	 如果MQ集群宕机，数据就会丢失，这时我们需要使用消息的持久化机制----durable
	   1) mp重启，就会失去我们之前创建的queue,所以首先先让queue持久化
	     channel.queueDeclare("queueName",true,false,false,null);   //第二个参数是创建queue的durable，也就是支持持久化
		 此时MQ重启时，可以恢复queue的信息，但是queue的message数据时没办法恢复的
		 
		2) 在生产者发送消息到mq时，需要定义这条消息也是durable
		channel.basicPublish("","queue_name",MessageProperties.PERSISTENT_TEXT_PLAIN,message.getBytes());
		注意：RabbitMq的消息持久化，是不承诺100%的消息不丢失的，可能因为mq接收到消息，但是还没来及持久化到磁盘，
		他自己就宕机了，这时候消息还是会丢失的。
		
	
	5.  unack消息积压问题，以及prefetch count参数设置
	    参考文章： https://www.cnblogs.com/jajian/p/10293391.html
		** unack消息积压问题
			对于每个channel,可以理解为一个消费者实例（比如一个仓储服务实例），其实都会有一些处于unack状态的消息。
			比如rabbitmq正在投递的一条消息到channel,此时消息状态时unack的；仓储服务实例接收到消息，处理期间(还没ack),此时的
			消息状态也时unack的；即使执行了ack操作，因为ack是异步执行的，在rabbitmq感知之前，消息状态也是unack的。
			如果unack的消息过多，一直积压着，可能会导致消费者服务实例的内存溢出问题。
		** prefetch count参数设置
            由于上述原因，rabbitmq基于prefetch count来控制这个unack message的数量
            可以通过channel.basicQos(10)这个方法来设置当前的channel的prefetch count,如果设置的是10,意味着当前这个channel里，
            unack message的数量不能超过10个，以此避免消费者服务实例积压unack meaasge过多。如果一个channel里的unack message
            超过了prefetch count指定的数量，此时rabbitmq 就会停止给这个channel投递消息，必须等待已经投递过去的消息ack了，才会
            投递下一个消息。
        ** prefetch count 设置多少合适？
		     1）假如设置的过大，100000条，在高并发大流量下，可能会导致消费者服务的内存被快速的消耗掉。
			       假如你的消费者服务内存积压着10万条消息，都是unack状态的，结果导致消费者服务实例内存溢出，服务宕机，然后大量的
				   unack消息会被重新投递给其他的存活的消费者服务实例，结果一样，导致宕机，左后导致雪崩效应。
				   
			 2）假如设置的为1，rabbitmq最多投递给你1条消息 处于unack状态，此时你刚处理完这条消息，然后执行了ack操作，由于ack是
				  异步的，假如需要100ms之后rabbitmq才会感知到，也就是100ms之后rabbitmq才会投递下一条消息，那么在着100ms内，你的
			 	 消费者服务什么都没干，导致消费者服务处理消息的吞吐量下降。
				 
			3) 所以鉴于上面两种极端情况，RabbitMQ官方给出的建议是prefetch count一般设置在100~300之间。
                 也就是一个消费者服务最多接收到100~300个message来处理，允许处于unack状态
		
			
		6.生产者投递消息丢失或消息还未来得及持久化丢失问题
		如果投递出去的消息在网络传输过程中丢失，或者RabbitMq的内存中还没写入磁盘的时候宕机，都会导致生产者投递到MQ的数据丢失
		** 保证投递消息不丢失的confirm机制
		    就是在生产端首先开启一个confirm模式，接着投递到MQ的消息，如果MQ一旦将消息持久化到磁盘之后，必须也传回一个confirm
			消息给生产者。如果没收到这个confirm消息，就说明这个消息可能丢失了。此时就可以重新投递消息
			一旦开启的confirm模式后，每次消息投递也同样有一个delivery tag的，也是起到唯一标识一次消息投递的作用。
			这样MQ回传ack给生产者的时候，会带上这个delivery tag,你就知道具体对应哪一个消息投递了，可以删除这条消息
		** 如果rabbitmq接收到一条消息之后，结果内部出错，发现无法处理这条消息，那么mq会回传一个nack消息给生产者。这时候
		    你可以选择重新投递这条消息
		** 另外一种情况，如果某条消息很长时间都没回传ack/nack,那可能是极端意外情况发生了，数据也丢失了，你也可以自己重新投递消息
		    到MQ去
		** confirm模式代码实现
     		//生产者设置confirm模式
			channel.confirmSelect();
			channel.addConfirmListener(new ConfirmListener(){
			       
				   //处理MQ回传的ack消息，收到这个ack消息，说明发送的消息被MQ给confirm了，持久化到磁盘了
				   public void handleAck(long deliveryTag,boolean mutiple) throws IOException{
				         //也可以把发送出去的，但是还没ack的消息，先保存在内存/数据库/缓存/kv存储
						 //然后收到这个消息的ack之后，你就可以将那个消息删除了
						 //deliveryTag就是消息的唯一标识
				   }
				   
				    public void handleNack(long deliveryTag,boolean mutiple) throws IOException{
					      //这里，如果收到消息的nack通知，那么可以选择重新投递消息
					}
			});
		
	       ** confirm机制的高延迟性
		        一旦开启了confirm机制，MQ并不保证什么时候会给你ack或者nack的，因为rabbitmq自己内部将消息持久化到
				磁盘，本身就是通过异步批量的方式进行的。正常情况下，投递的消息会先驻留在内存中，然后过了几百毫秒的延迟时间后，
				再一次性批量把多条消息持久化磁盘中，这样是为了兼顾高并发写入的吞吐量和性能的，因为要是来一条消息就写一次磁盘，
				那么性能会很差，每次写磁盘都是一次fsync强制刷入磁盘的操作，是很耗时的。
		 
		 ** 高并发下如何投递消息才能不丢失
		     1） 首先：每次写一条消息到MQ中，为了等待这条消息的ack，必须把消息保存到某个存储里，这个存储不就建议是内存，因为高并发下
			       消息会很多，每秒可能是几千甚至上万的消息，消息的ack要等几百毫秒的话，放在内存会有溢出的风险。建议采用kv存储，kv存储
				   承载高并发能力极强，而且kv操作性能很高
			  2)  其次：绝不能同步写消息+等待ack的方式来投递，那样会导致每次投递一个消息都同步阻塞等待几百毫秒，这样会导致投递性能和吞吐
			     量大幅度下降。  投递消息后等待ack的过程必须是异步的，也就是类似上面那样的代码，以及给出了一个初步的异步回调方式。消息投递
				 出去之后，这个投递的线程其实就可以返回了，至于每个消息的异步回调，就像上述代码，通过在channel注册一个confirm监听器实现的。
				 收到一个ack之后，就从kv存储中删除这条临时消息； 收到一个nack之后，就从kv存储提取这条消息然后重新投递一次。也可以自己对kv
				 存储的消息做监控，如果超过一定时长没有收到ack，就主动重发消息。
				 
				 
				 
				 
				 
		7. rabbitmq使用中常见的坑
		   1)  启用ack机制后，没有及时的ack导致的队列异常
		        var channel = GetChannel();
				var consumer = new EventingBasicConsumer(channel);
				// 开启acknowledge机制，在接收事件里ack
				channel.BasicConsume(queue, false, consumer);
				consumer.Received += (sender, e) =>
				{
					try{
						callback(e.Body, e.BasicProperties.Headers);
						// 无异常时，发ack通知mq丢弃消息        
						((EventingBasicConsumer)sender).Model.BasicAck(e.DeliveryTag, false);  
					}catch (Exception exp){
					     //有异常不做ack通知
						LogHelper.Info(exp);
					}
				}
	            这段代码，先处理消息，完成后，再做ack处理，失败就不做ack响应，这样消息会存储在MQ的Unacked消息里，
				不会丢失，看起来不会有问题。但是业务代码有问题，所有消费的消息都出现异常，这会导致unacked的消息数量
				暴涨，导致MQ响应越来越慢，甚至崩溃的问题。
				原因是如果MQ没得到ack响应，这些消息会堆积在unacked消息里，不会抛弃，直至客户端断开重连，才会变回ready;
				如果客户端不断开连接，这些unacked消息，永远不会变回ready状态，unacked消息多了，占用内存越来越大，就会停止给这个channel投递消息，必须等待已经投递过去的消息ack了，才会
				导致异常，解决办法就是及时去ack消息。
				
				
			 2) 启用nack机制后，导致的死循环
			    var channel = GetChannel();
				var consumer = new EventingBasicConsumer(channel);
				// 开启acknowledge机制，在接收事件里ack
				channel.BasicConsume(queue, false, consumer);
				consumer.Received += (sender, e) =>
				{
					try{
						callback(e.Body, e.BasicProperties.Headers);
						//无异常，通知mq删除消息
						((EventingBasicConsumer) sender).Model.BasicAck(e.DeliveryTag, false);
					}catch (Exception exp){
						LogHelper.Info(exp);
						// 出错了，发nack，并通知MQ把消息塞回的队列头部（不是尾部）
						((EventingBasicConsumer) sender).Model.BasicNack(e.DeliveryTag, false, true);
					}
				};
               如上代码，正常就ack，异常就发nack通知，并等待下次重新消费。这是如果还是所有消息都异常，都发出了nack通知，
				把消息重新塞回到队列头部，下一步消费这条消息由出现异常，由重回队列，进入死循环，导致堆积........
				
