snowflake：雪花算法 

一. snowflake算法生成id的结果是一个64bit大小的整数

 1.示例 
    0 - 00000000 00000000 00000000 00000000 00000000 0 - 00000000 00 - 00000000 0000

 2. 组成部分 
    
	a: 1bit 
	   不用，因为二进制种最高位是符号位，1表示负数，0表示正数，生成的id一般都是用整数，所以最高位固定为0
	b: 41bit (时间戳，用来记录时间戳，毫秒级)
	   -- 41位可以表示2^41-1个数字 
	   -- 如果只用来表示正整数（计算机中正数包含0），可以表示的数值范围是0至2^41-1,减1是因为可表示的数值范围是从0开始算的，而不是1.
	   -- 也就是说41位可以表述2^41-1个毫秒的值，转化程单位年则是 (2^41-1)/(1000*60*60*24*365)=69年
    c: 10bit(工作机器id),用来记录工作机器id 
	   -- 可以部署在2^10=1024个结点，包括5位datacenterid和5位workid
       -- 5位(bit) 可以表示的最大正整数是2^5-1= 31，即可以用0,1,2,......,31这32个数字，来表示不同的datacenterid或workerid 
	d: 12bit(序列号) 用来记录桶毫秒内产生的不同id
	   -- 12bit可以表示的最大正整数2^12-1 = 4095,即可以用0,1,2,3,....,4095这4096个数字，来表示同一机器同一时间戳内产生4095个ID序号
	   
	由于在java中64bit的整数是long类型，所以在java中SnowFlake算法生成的id就是long来存储

 3. 保证：
    a: 所有生成的id按时间趋势递增
    b：整个分布式系统内不会产生重复id (因为有datacenterid和workerid来做区分)
	
	
	
	
	
	
	
第一部分：0 -- 固定 
第二部分：时间戳(毫秒级)，这里为41bit
第三部分：工作机器id，一般为5bit数据中心id(datacenterid)+5bit机器id(workid)组成，10位的长度最多支持部署1024个结点 
第四部分：在相同毫秒内，可以产生2^12个id，12位的计数顺序号支持每个结点每毫秒产生4096个id序列 
	
	
	
	
	
	
	
	
	
	
类snowflake方案:    https://tech.meituan.com/2017/04/21/mt-leaf.html

一. 美团leaf-segment数据库方案
    第一种leaf-segment方案，在使用数据库的方案上，做了如下改变： -- 原方案每次获取ID都要读写一次数据库，造成数据库压力，改为利用proxy server批量获取，
	每次获取一个segment（step决定大小）号段的值，用完之后再去数据库获取新的号段，可以大大减轻数据库的压力，各个业务不同的发号需求用biz_tag字段来区分，
	每个biz_tag的ID获取相互隔离，互不影响。如果以后有性能需求需要对数据库扩容，不需要上述描述的复杂的扩容操作，只需要对biz_tag分库分表就行。
	数据库设计如下：
	
		+-------------+--------------+------+-----+-------------------+-----------------------------+
	| Field       | Type         | Null | Key | Default           | Extra                       |
	+-------------+--------------+------+-----+-------------------+-----------------------------+
	| biz_tag     | varchar(128) | NO   | PRI |                   |                             |
	| max_id      | bigint(20)   | NO   |     | 1                 |                             |
	| step        | int(11)      | NO   |     | NULL              |                             |
	| desc        | varchar(256) | YES  |     | NULL              |                             |
	| update_time | timestamp    | NO   |     | CURRENT_TIMESTAMP | on update CURRENT_TIMESTAMP |
    
	重要字段说明: biz_tag用来区分业务,max_id表示该biz_tag目前所被分配的ID号段的最大值，step表示每次分配的号段长度，原来获取ID每次都需要写数据库，现在只需要把step设置的
	足够大，比如1000，那么只有当1000个号被消耗完了之后才会去重新读写一次数据库，读写数据库的频率从1减小到了1/step


	
    优点： (1) leaf服务可以很方便的限行扩展，性能完全能够支撑大多数业务场景
	       (2) ID号码是趋势递增的8byte的64位数字，满足上述数据库存在的主键要求
		   (3) 容灾性高: leaf服务内部有号段缓存，即使DB宕机，短时间内leaf仍能正常对外提供服务
		   (4) 可以自定义max_id的大小，非常方便业务从原有的ID方式上迁移过来
	
	缺点：(1) ID号码不够随机，能够泄露发号数据量的信息，不太安全
	      (2) TP000数据波动大，当号段使用完之后还是会hang在更新数据库的I/O上，tg999数据会出现偶尔的尖刺
		  (3) DB宕机会造成整个系统不可用
		  
	
	
	
	双Buffer优化：
    对于第二个缺点，leaf-segment做了些优化，简单的说就是：
	
	Leaf取号段的时机是在号段消耗完的时候进行的，也就意味着号段临界点的ID下发时间取决于下一次从DB取回号段的时间，并且在这期间进来的请求也会因为
	DB号段没有取回来，导致线程阻塞。如果请求DB的网络和DB的性能稳定，这种情况对系统的影响是不大的，但是假如取DB的时候网络发生抖动，或者DB发生
	慢查询就会导致整个系统的响应时间变慢。
	
	为此，我们希望DB取号段的过程能够做到无阻塞，不需要在DB取号段的时候阻塞请求线程，即当号段消费到某个点时就异步的把下一个号段加载到内存中，而不需要等到号段
	用尽的时候才去更新号段，这样做就可以很大程度上降低系统的TP999的指标
	
	采用双Buffer的方式，leaf服务内部有两个号段缓存区segment。当前号段已下发10%时，如果下一个号段未更新，则另起一个更新线程区更新下一个号段，当前号段全部下发完
	后，如果下个号段准备好了则切换到下个号段为当前segment接下下发，循环往复
	

	** 每个biz-tag都有消费速度监控，通常推荐segment长度设置为服务高峰期发号QPS的600倍（10分钟），这样即使DB宕机，leaf仍能持续发号10-20分钟不受影响
	
	** 每次请求来临时都会判断下个号段的状态，从而更新此号段，所以偶尔的网络抖动不会影响下个号段的更新
	
	
	
	
	Leaf高可用容灾：
    实现数据库的高可用，主从切换 
	
	
	
	
	
	
二、leaf-snowflake方案 
    	
	0 - 00000000 00000000 00000000 00000000 00000000 0 - 00000000 00 - 00000000 0000
	第一部分：0 -- 固定 
	第二部分：时间戳(毫秒级)，这里为41bit
	第三部分：工作机器id，机器的唯一标识。
	第四部分：在相同毫秒内，可以产生2^12个id，12位的计数顺序号支持每个结点每毫秒产生4096个id序列 
	
	leaf-snowflake方案完全沿用snowflake方案的bit位设计，即是“1+41+10+12”的方式组装ID号，对于workerId的分配，当服务集群数量较小的情况下，
	完全可以手动配置，leaf服务规模较大，动手配置成本太高，所以使用Zookeeper持久顺序节点的特性自动对snowflake节点配置wrokerid。leaf-snowflake
	是按照下面几个步骤启动的：
	（1） 启动Leaf-snowflake服务，连接zookeeper，在leaf_forever父节点下检查自己是否已经注册过（是否有该顺序子节点）
	（2） 如果有注册过直接取回自己的workerId(zk顺序节点生成的int类型ID号)，启动服务
	（3） 如果没有注册过，就在该父节点下创建一个持久顺序节点，创建成功后取回顺序号当作自己的workerid号，启动服务
	
	
	
	
	
	
	
	






















































































	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	















