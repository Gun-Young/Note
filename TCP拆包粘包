TCP 粘包拆包

一.场景
   假设客户端发送了两个数据包D1和D2给服务端，由于服务端一次读取到的字节数是不确定的，可能存在四种情况：
   1. 服务端分两次读取到了两个独立的数据包，分别时D1和D2,没有粘包和拆包
   2. 服务端一次接收到了两个数据包，D1和D2粘合在一起，被称为TCP粘包
   3. 服务端分两次读取了两个数据包，第一次读取了完整的D1和D2包的一部分，第二次读读取到了D2包的剩余内容，被称为TCP拆包
   4.服务端分两次读读取到了两个数据包，第一次读取了D1的部分内容，第二次读取了D1包的剩余部分和D2完整包。
   
   
 
 二.产生原因：
	 1.应用程序write写入的字节大小大于套接口发送缓冲区大小
	 2.进行MSS大小的TCP分段
	 3.以太网帧的payload大于MTU进行IP分片
	 解释1：
	 TCP是以流的方式传输数据，传输的最小单位为一个报文段(segment),tcp header中有个Options标识，
	 常见的标识为mss(Maximum Segment Size)指的是，连接层每次传输的数据有个最大限制，MTU(Maximum Transmission Unit),
	 一般是1500bit,超过这个量要分成多个报文段，mss则是这个最大限制减去TCP的header,光是要传输的数据大小，一般是1460bit,
	 换成字节，也就是180多字节。
	 TCP为提高性能，发送端会将需要发送的数据发送到缓冲区，等待缓冲区满了之后，再将缓冲区中的数据发送到接收方，
	 同理，接收方也有缓冲区这样的机制，来接收数据
	 
	 解释2：
	 发送方原因：TCP默认使用Nagle算法，而Nagle算法主要做的两件事：只有上一个分组得到确认，才发送下一个分组，
	                      收集多个小分组，在一个确认到来时一起发送，Nagle算法造成了发送方可能存在粘包现象
	 接收方原因： TCP接收到分组时，应用层程序不会立即处理，TCP将接收的分组放到缓存中，然后应用程序主动从缓存中
						 读取分组，当TCP接收分组的速度大于应用程序读取分组的速度时，多个包就会被存放在缓存中，应用程度读取时，就会
						 读取多个首尾相连在一起的包
	 
	 
	 
	 

三.粘包拆包的解决办法
    无论TCP的拆包和TCP粘包本质问题就是无法区分包的界限，可用以下三种办法区分包的界限
	1. 消息定长，比如每个报文的大小为固定的长度200字节，如果不够，空位补空格
	2.在包尾增加分割符
	3.将消息分为消息头和消息体，消息头要包含表示消息体的总长度的字段。





四. Nagle算法：
        TCP/IP协议中，无论发送多少数据，总是要在数据(DATA)前面加上协议头(TCP Header+IP Header)，同时，对方接收到数据，也需要发送ACK表示确认。
即使从键盘输入的一个字符，占用一个字节，可能在传输上造成41字节的包，其中包括1字节的有用信息和40字节的首部数据。这种情况转变成了4000%的消耗，这样的情况对于重负载的网络来是无法接受的。
为了尽可能的利用网络带宽，TCP总是希望尽可能的发送足够大的数据。（一个连接会设置MSS参数，因此，TCP/IP希望每次都能够以MSS尺寸的数据块来发送数据）。

        Nagle算法就是为了尽可能发送大块数据，避免网络中充斥着许多小数据块。
        Nagle算法的基本定义是任意时刻，最多只能有一个未被确认的小段。 所谓“小段”，指的是小于MSS尺寸的数据块，所谓“未被确认”，是指一个数据块发送出去后，没有收到对方发送的ACK确认该数据已收到。
    Nagle算法的规则：
		1.如果SO_SNDBUF(发送缓冲区）中的数据长度达到MSS，则允许发送；
		2.如果该SO_SNDBUF中含有FIN，表示请求关闭连接，则先将SO_SNDBUF中的剩余数据发送，再关闭；
		3.设置了TCP_NODELAY=true选项，则允许发送。TCP_NODELAY是取消TCP的确认延迟机制，相当于禁用了Nagle 算法。
		4.未设置TCP_CORK选项时，若所有发出去的小数据包（包长度小于MSS）均被确认，则允许发送;
		5.上述条件都未满足，但发生了超时（一般为200ms），则立即发送。
	 
	 
	 
	 
	 
	 
	 
	 
-----------------------------------------------------------------------------------------------------
编解码技术

一. java 序列化
   
          java 提供的对象输入/输出流ObjectInputStream 和 ObjectOutStream，可以直接把java对象作为可存储的字节数组
   写入文件，也可以传输到网络上，基于JDK默认的序列化机制可以避免操作底层的字节数组，提高开发效率。
          当进行远程跨进程服务调用时，需要把传输的java对象编码为字节数组或者ByteBuffer对象，而远程服务读取到ByteBuffer
   对象或者字节数组时，需要将其解码为发送时的Java对象，这就是java的编解码技术。
          Java实现序列换不需要添加额外的类库，只需要实现java.io.Serializable并生成序列化ID即可。
	
   缺点：
      1.无法跨语言
	  2. 序列化后的码流太大（字节数字太大）
	  3.序列化性能太低
	  
	  
	  
	  
	  
二. google的Protobuf (Google protocol buffers)
	  它将数据结构以.proto文件进行描述，通过代码生成工具可以生成对应数据结构的POJO对象和Protobuf相关的方法和属性。
	  
	  特点：
	    1. 结构化数据存储格式（XML,JSON等）
		2.高效的编解码性能
		3.语言无关，平台无关，扩展性好
		4.官方支持Java，c++和Python三种语言
	  
	  Protobuf另一个吸引人的地方就是它的数据描述文件和代码生成机制，利用数据描述文件对数据结构进行说明的优点：
	   1.文本化的数据结构表述语言，可以实现语言可平台无关，特别适合异构系统件的集成
	   2.通过标识字段的顺序，可以实现协议的前向兼容
	   3.自动代码生成，不需要手工编写通常数据结构的C++或java版本
	   4.方便后续的管理和维护，相比于代码，结构化的文档更容易管理和维护
	   
	   很多RPC框架选用Protobuf做编解码框架
	   
	   
	   
	   
	   
三. Facebook 的Thrift
      Thrift支持多种程序语言，C++,C# ,Cocoa,Erlang,Haskell,Java,Ocami,Perl,PHP,Python,Ruby,smalltalk
	  在多种不同语言之间通信，Thrift可以作为高性能的通信中间件使用，它支持数据(对象)序列化和多种类型的
	  RPC服务，Thrift适用于静态的数据交换，需要先确定好它的数据结构，当数据结构发生变化时，必须重新编辑
	  IDL文件，生成代码和编译，这一点是弱项。Thrift适用于搭建大型数据交换及存储的通用工具，对于大型系统中
	  的内部数据传输，相对于JSON和XML在性能和传输大小上有明显的优势
	  
   
     
	 
四. JBoos Marshalling
    它是一个Java对象的序列化API包，优化可JDK序列化问题和性能
	相比于java序列化机制，优点如下：
	1.可插拔的类解析器，提供更加便捷的类加载定制册罗，通过一个接口即可实现定制
	2.可插拔的对象替换技术，不需要通过继承的方式
	3.可插拔的预定义类缓存表，可以减少序列化的字节数组长度，提供常用类型的独享序列化性能
	4.无须实现java.io.Serializable接口，即可实现java序列化
	5.通过缓存技术提升对象的序列化性能
	
	JBoos Marshalling更多是在JBoss内部适用，应用范围有限
	



-------------------------------------------------------------

netty事件分为inbound和outbound事件，inbound事件通常由IO线程触发，
例如：TCP链路建立事件，链路关闭事件，都时间，异常通知事件


outbound 事件通常是由用户主动发起的网络IO事件，例如用户发起连接操作，
绑定操作，消息发送等



ChannelHandler功能
@Sharable：多个ChannelPipeline共用一个ChannelHandler
@Skip：被Skip注解的方法不会被调用，直接被忽略









